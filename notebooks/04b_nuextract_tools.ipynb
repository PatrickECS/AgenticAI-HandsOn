{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd4d31e-4f6b-467c-981c-3cff613d913e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from rich.pretty import pprint\n",
    "from phi.agent import Agent\n",
    "from phi.model.ollama import OllamaTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1766def-8ba0-4f41-9fb8-4e337835535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OLLAMA_HOST=\"localhost\"\n",
    "#OLLAMA_HOST=\"ollama.ollama.svc.cluster.local\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3d326-34ca-4836-88fc-58c43dece30c",
   "metadata": {},
   "source": [
    "First we'll create our own tool for structured extraction like in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2db7fa-0c67-42ff-afbb-8f028363cd79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from phi.tools import Toolkit\n",
    "from phi.model.ollama import Ollama\n",
    "from phi.utils.log import logger\n",
    "\n",
    "class NuExtractTools(Toolkit):\n",
    "    def __init__(self, json_template: str):\n",
    "        super().__init__(name=\"nuextract_tools\")\n",
    "        self.json_template = json_template\n",
    "        self.extract_agent = Agent(\n",
    "            model=Ollama(id=\"sroecker/nuextract-tiny-v1.5\", host=OLLAMA_HOST, options={\"temperature\": 0}),\n",
    "            markdown=False,\n",
    "            structured_outputs=True\n",
    "        )\n",
    "        self.register(self.predict_nuextract)\n",
    "\n",
    "        \n",
    "    def predict_nuextract(self, input_text: str) -> str:\n",
    "        \"\"\"Extracts structured information and returns JSON.\n",
    "        \n",
    "        Args:\n",
    "            input_text (str): The input text to extract information from.\n",
    "        Returns:\n",
    "            str: The output in JSON.\n",
    "        \"\"\"\n",
    "        template = f\"\"\"<|input|>\\n### Template:\\n{self.json_template}\\n### Text:\\n{input_text}\\n\\n<|output|>\"\"\"\n",
    "        logger.info(f\"Extracting structured data according to schema: {self.json_template}\")\n",
    "        output_json = self.extract_agent.run(template, stream=False)\n",
    "        \n",
    "        return output_json.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e7d0c0-443e-45f5-8882-9c9017f1a487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_template = \"\"\"\n",
    "    {\n",
    "        \"Model\": {\n",
    "            \"Name\": \"\",\n",
    "            \"Number of parameters\": \"\",\n",
    "            \"Number of max token\": \"\",\n",
    "            \"Architecture\": []\n",
    "        },\n",
    "        \"Usage\": {\n",
    "            \"Use case\": [],\n",
    "            \"Licence\": \"\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0e206b-683d-4edb-b66c-450c9f695e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_text = \"\"\"We introduce Mistral 7B, a 7–billion-parameter language model engineered for\n",
    "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
    "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
    "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
    "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
    "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
    "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
    "Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and\n",
    "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
    "Code: <https://github.com/mistralai/mistral-src>\n",
    "Webpage: <https://mistral.ai/news/announcing-mistral-7b/>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59970eac-81d7-4077-b4c3-999098e09085",
   "metadata": {},
   "source": [
    "Now we're using a normal LLM that can use the NuExtract tool that we just implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2641800a-4053-49cd-b689-9ed18a2c990b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Debug logs enabled                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Debug logs enabled                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_agent = Agent(\n",
    "    model=Ollama(id=\"hermes3:8b-llama3.1-q8_0\", host=OLLAMA_HOST),\n",
    "    description=\"You extract structured information.\",\n",
    "    tools=[NuExtractTools(json_template)],\n",
    "    instructions=[\"Extract and output structured information from the provided text with your tools.\"],\n",
    "    show_tool_calls=True,\n",
    "    debug_mode=True,\n",
    "    markdown=True,\n",
    "    structured_outputs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d975ed6d-4bb7-40ef-b6c3-1303cfb4064a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> *********** Agent Run Start: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">6ffdbc1c-c9d2-4f9a-aa18-6caf9a8f99ea</span> ***********                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m *********** Agent Run Start: \u001b[93m6ffdbc1c-c9d2-4f9a-aa18-6caf9a8f99ea\u001b[0m ***********                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Function predict_nuextract from nuextract_tools added to model.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Function predict_nuextract from nuextract_tools added to model.                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- Ollama Response Start ----------                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- Ollama Response Start ----------                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== system ==============                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== system ==============                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> You extract structured information.                                                                       \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Extract and output structured information from the provided text with your tools.                       \n",
       "         - Use markdown to format your answers.                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m You extract structured information.                                                                       \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Extract and output structured information from the provided text with your tools.                       \n",
       "         - Use markdown to format your answers.                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== user ==============                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== user ==============                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> We introduce Mistral 7B, a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>–billion-parameter language model engineered for                              \n",
       "         superior performance and efficiency. Mistral 7B outperforms the best open 13B                             \n",
       "         model <span style=\"font-weight: bold\">(</span>Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> across all evaluated benchmarks, and the best released 34B                                \n",
       "         model <span style=\"font-weight: bold\">(</span>Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> in reasoning, mathematics, and code generation. Our model                                 \n",
       "         leverages grouped-query attention <span style=\"font-weight: bold\">(</span>GQA<span style=\"font-weight: bold\">)</span> for faster inference, coupled with sliding                        \n",
       "         window attention <span style=\"font-weight: bold\">(</span>SWA<span style=\"font-weight: bold\">)</span> to effectively handle sequences of arbitrary length with a                         \n",
       "         reduced inference cost. We also provide a model fine-tuned to follow instructions,                        \n",
       "         Mistral 7B – Instruct, that surpasses Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> 13B – chat model both on human and                          \n",
       "         automated benchmarks. Our models are released under the Apache <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span> license.                               \n",
       "         Code: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/mistralai/mistral-src</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                          \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">Webpage: &lt;</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://mistral.ai/news/announcing-mistral-7b/</span><span style=\"font-weight: bold\">&gt;</span>                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m We introduce Mistral 7B, a \u001b[1;36m7\u001b[0m–billion-parameter language model engineered for                              \n",
       "         superior performance and efficiency. Mistral 7B outperforms the best open 13B                             \n",
       "         model \u001b[1m(\u001b[0mLlama \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m across all evaluated benchmarks, and the best released 34B                                \n",
       "         model \u001b[1m(\u001b[0mLlama \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m in reasoning, mathematics, and code generation. Our model                                 \n",
       "         leverages grouped-query attention \u001b[1m(\u001b[0mGQA\u001b[1m)\u001b[0m for faster inference, coupled with sliding                        \n",
       "         window attention \u001b[1m(\u001b[0mSWA\u001b[1m)\u001b[0m to effectively handle sequences of arbitrary length with a                         \n",
       "         reduced inference cost. We also provide a model fine-tuned to follow instructions,                        \n",
       "         Mistral 7B – Instruct, that surpasses Llama \u001b[1;36m2\u001b[0m 13B – chat model both on human and                          \n",
       "         automated benchmarks. Our models are released under the Apache \u001b[1;36m2.0\u001b[0m license.                               \n",
       "         Code: \u001b[1m<\u001b[0m\u001b[4;94mhttps:\u001b[0m\u001b[4;94m//github.com/mistralai/mistral-src\u001b[0m\u001b[39m>\u001b[0m                                                          \n",
       "         \u001b[39mWebpage: <\u001b[0m\u001b[4;94mhttps://mistral.ai/news/announcing-mistral-7b/\u001b[0m\u001b[1m>\u001b[0m                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6952d24aa0784a83aa2aea10f5cbcd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== assistant ==============                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== assistant ==============                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Tool Calls: <span style=\"font-weight: bold\">[</span>                                                                                             \n",
       "           <span style=\"font-weight: bold\">{</span>                                                                                                       \n",
       "             <span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"function\"</span>,                                                                                   \n",
       "             <span style=\"color: #008000; text-decoration-color: #008000\">\"function\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                         \n",
       "               <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"predict_nuextract\"</span>,                                                                        \n",
       "               <span style=\"color: #008000; text-decoration-color: #008000\">\"arguments\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"input_text\\\": \\\"We introduce Mistral 7B, a 7\\\\u2013billion-parameter language model</span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">engineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model (Llama </span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">2) across all evaluated benchmarks, and the best released 34B model (Llama 1) in reasoning, mathematics, </span> \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with </span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced </span>        \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B \\\\u2013 Instruct, </span>  \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">that surpasses Llama 2 13B \\\\u2013 chat model both on human and automated benchmarks. Our models are </span>     \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">released under the Apache 2.0 license. Code: https://github.com/mistralai/mistral-src Webpage: </span>           \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">https://mistral.ai/news/announcing-mistral-7b/\\\"}\"</span>                                                        \n",
       "             <span style=\"font-weight: bold\">}</span>                                                                                                     \n",
       "           <span style=\"font-weight: bold\">}</span>                                                                                                       \n",
       "         <span style=\"font-weight: bold\">]</span>                                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Tool Calls: \u001b[1m[\u001b[0m                                                                                             \n",
       "           \u001b[1m{\u001b[0m                                                                                                       \n",
       "             \u001b[32m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,                                                                                   \n",
       "             \u001b[32m\"function\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                         \n",
       "               \u001b[32m\"name\"\u001b[0m: \u001b[32m\"predict_nuextract\"\u001b[0m,                                                                        \n",
       "               \u001b[32m\"arguments\"\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"input_text\\\": \\\"We introduce Mistral 7B, a 7\\\\u2013billion-parameter language model\u001b[0m\n",
       "         \u001b[32mengineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLlama \u001b[0m\n",
       "         \u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m across all evaluated benchmarks, and the best released 34B model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLlama 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in reasoning, mathematics, \u001b[0m \n",
       "         \u001b[32mand code generation. Our model leverages grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for faster inference, coupled with \u001b[0m\n",
       "         \u001b[32msliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to effectively handle sequences of arbitrary length with a reduced \u001b[0m        \n",
       "         \u001b[32minference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B \\\\u2013 Instruct, \u001b[0m  \n",
       "         \u001b[32mthat surpasses Llama 2 13B \\\\u2013 chat model both on human and automated benchmarks. Our models are \u001b[0m     \n",
       "         \u001b[32mreleased under the Apache 2.0 license. Code: https://github.com/mistralai/mistral-src Webpage: \u001b[0m           \n",
       "         \u001b[32mhttps://mistral.ai/news/announcing-mistral-7b/\\\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m                                                        \n",
       "             \u001b[1m}\u001b[0m                                                                                                     \n",
       "           \u001b[1m}\u001b[0m                                                                                                       \n",
       "         \u001b[1m]\u001b[0m                                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS START ****************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS START ****************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Time to generate response:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>6115s                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Time to generate response:   \u001b[1;36m13.\u001b[0m6115s                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Tokens per second:           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.1629</span> tokens/s                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Tokens per second:           \u001b[1;36m16.1629\u001b[0m tokens/s                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Input tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">507</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Input tokens:                \u001b[1;36m507\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Output tokens:               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">220</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Output tokens:               \u001b[1;36m220\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Total tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">727</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Total tokens:                \u001b[1;36m727\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS END ******************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS END ******************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Getting function predict_nuextract                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Getting function predict_nuextract                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Running: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">predict_nuextract</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_text</span>=<span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Running: \u001b[1;35mpredict_nuextract\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_text\u001b[0m=\u001b[33m...\u001b[0m\u001b[1m)\u001b[0m                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Extracting structured data according to schema:                                                           \n",
       "             <span style=\"font-weight: bold\">{</span>                                                                                                     \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Model\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,                                                                                   \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of parameters\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,                                                                   \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of max token\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,                                                                    \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Architecture\"</span>: <span style=\"font-weight: bold\">[]</span>                                                                            \n",
       "                 <span style=\"font-weight: bold\">}</span>,                                                                                                \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Usage\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Use case\"</span>: <span style=\"font-weight: bold\">[]</span>,                                                                               \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Licence\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>                                                                                 \n",
       "                 <span style=\"font-weight: bold\">}</span>                                                                                                 \n",
       "             <span style=\"font-weight: bold\">}</span>                                                                                                     \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Extracting structured data according to schema:                                                           \n",
       "             \u001b[1m{\u001b[0m                                                                                                     \n",
       "                 \u001b[32m\"Model\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Name\"\u001b[0m: \u001b[32m\"\"\u001b[0m,                                                                                   \n",
       "                     \u001b[32m\"Number of parameters\"\u001b[0m: \u001b[32m\"\"\u001b[0m,                                                                   \n",
       "                     \u001b[32m\"Number of max token\"\u001b[0m: \u001b[32m\"\"\u001b[0m,                                                                    \n",
       "                     \u001b[32m\"Architecture\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                                                            \n",
       "                 \u001b[1m}\u001b[0m,                                                                                                \n",
       "                 \u001b[32m\"Usage\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Use case\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,                                                                               \n",
       "                     \u001b[32m\"Licence\"\u001b[0m: \u001b[32m\"\"\u001b[0m                                                                                 \n",
       "                 \u001b[1m}\u001b[0m                                                                                                 \n",
       "             \u001b[1m}\u001b[0m                                                                                                     \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> *********** Agent Run Start: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">598206ad-718f-42b6-942e-2ce0ebb122f1</span> ***********                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m *********** Agent Run Start: \u001b[93m598206ad-718f-42b6-942e-2ce0ebb122f1\u001b[0m ***********                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- Ollama Response Start ----------                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- Ollama Response Start ----------                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== user ==============                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== user ==============                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">|input|</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                                                                 \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">### Template:</span>                                                                                             \n",
       "                                                                                                                   \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>                                                                                                     \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Model\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>                                                                                        \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Name\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>                                                                                   \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Number of parameters\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>                                                                   \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Number of max token\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>                                                                    \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Architecture\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[]</span>                                                                            \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>                                                                                                \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Usage\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>                                                                                        \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Use case\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>                                                                               \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Licence\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>                                                                                 \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                                                                                                 \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span>                                                                                                     \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">    </span>                                                                                                      \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">### Text:</span>                                                                                                 \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">We introduce Mistral 7B, a </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #000000; text-decoration-color: #000000\">–billion-parameter language model engineered for superior performance and </span>    \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">efficiency. Mistral 7B outperforms the best open 13B model </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">Llama </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> across all evaluated benchmarks, and </span>\n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">the best released 34B model </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">Llama </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> in reasoning, mathematics, and code generation. Our model leverages </span>\n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">grouped-query attention </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">GQA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> for faster inference, coupled with sliding window attention </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">SWA</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> to </span>       \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model </span>  \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">fine-tuned to follow instructions, Mistral 7B – Instruct, that surpasses Llama </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\"> 13B – chat model both on </span>\n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">human and automated benchmarks. Our models are released under the Apache </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span><span style=\"color: #000000; text-decoration-color: #000000\"> license. Code: </span>              \n",
       "         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/mistralai/mistral-src</span><span style=\"color: #000000; text-decoration-color: #000000\"> Webpage: </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://mistral.ai/news/announcing-mistral-7b/</span>          \n",
       "                                                                                                                   \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">&lt;|output|</span><span style=\"font-weight: bold\">&gt;</span>                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m \u001b[1m<\u001b[0m\u001b[1;95m|input|\u001b[0m\u001b[39m>\u001b[0m                                                                                                 \n",
       "         \u001b[39m### Template:\u001b[0m                                                                                             \n",
       "                                                                                                                   \n",
       "         \u001b[39m    \u001b[0m\u001b[1;39m{\u001b[0m                                                                                                     \n",
       "         \u001b[39m        \u001b[0m\u001b[32m\"Model\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m                                                                                        \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Name\"\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"\"\u001b[0m\u001b[39m,\u001b[0m                                                                                   \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Number of parameters\"\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"\"\u001b[0m\u001b[39m,\u001b[0m                                                                   \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Number of max token\"\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"\"\u001b[0m\u001b[39m,\u001b[0m                                                                    \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Architecture\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m]\u001b[0m                                                                            \n",
       "         \u001b[39m        \u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                                                                                                \n",
       "         \u001b[39m        \u001b[0m\u001b[32m\"Usage\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m                                                                                        \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Use case\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                                                                               \n",
       "         \u001b[39m            \u001b[0m\u001b[32m\"Licence\"\u001b[0m\u001b[39m: \u001b[0m\u001b[32m\"\"\u001b[0m                                                                                 \n",
       "         \u001b[39m        \u001b[0m\u001b[1;39m}\u001b[0m                                                                                                 \n",
       "         \u001b[39m    \u001b[0m\u001b[1;39m}\u001b[0m                                                                                                     \n",
       "         \u001b[39m    \u001b[0m                                                                                                      \n",
       "         \u001b[39m### Text:\u001b[0m                                                                                                 \n",
       "         \u001b[39mWe introduce Mistral 7B, a \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m–billion-parameter language model engineered for superior performance and \u001b[0m    \n",
       "         \u001b[39mefficiency. Mistral 7B outperforms the best open 13B model \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mLlama \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m across all evaluated benchmarks, and \u001b[0m\n",
       "         \u001b[39mthe best released 34B model \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mLlama \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m in reasoning, mathematics, and code generation. Our model leverages \u001b[0m\n",
       "         \u001b[39mgrouped-query attention \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mGQA\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m for faster inference, coupled with sliding window attention \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mSWA\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m to \u001b[0m       \n",
       "         \u001b[39meffectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model \u001b[0m  \n",
       "         \u001b[39mfine-tuned to follow instructions, Mistral 7B – Instruct, that surpasses Llama \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m 13B – chat model both on \u001b[0m\n",
       "         \u001b[39mhuman and automated benchmarks. Our models are released under the Apache \u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[39m license. Code: \u001b[0m              \n",
       "         \u001b[4;94mhttps://github.com/mistralai/mistral-src\u001b[0m\u001b[39m Webpage: \u001b[0m\u001b[4;94mhttps://mistral.ai/news/announcing-mistral-7b/\u001b[0m          \n",
       "                                                                                                                   \n",
       "         \u001b[39m<|output|\u001b[0m\u001b[1m>\u001b[0m                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== assistant ==============                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== assistant ==============                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span>     <span style=\"font-weight: bold\">{</span>                                                                                                     \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Model\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Mistral 7B\"</span>,                                                                         \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of parameters\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"7\\u2013billion\"</span>,                                                     \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of max token\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,                                                                    \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Architecture\"</span>: <span style=\"font-weight: bold\">[</span>                                                                             \n",
       "                         <span style=\"color: #008000; text-decoration-color: #008000\">\"grouped-query attention (GQA)\"</span>,                                                          \n",
       "                         <span style=\"color: #008000; text-decoration-color: #008000\">\"sliding window attention (SWA)\"</span>                                                          \n",
       "                     <span style=\"font-weight: bold\">]</span>                                                                                             \n",
       "                 <span style=\"font-weight: bold\">}</span>,                                                                                                \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Usage\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Use case\"</span>: <span style=\"font-weight: bold\">[]</span>,                                                                               \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Licence\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Apache 2.0\"</span>                                                                       \n",
       "                 <span style=\"font-weight: bold\">}</span>                                                                                                 \n",
       "             <span style=\"font-weight: bold\">}</span>                                                                                                     \n",
       "                                                                                                                   \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m     \u001b[1m{\u001b[0m                                                                                                     \n",
       "                 \u001b[32m\"Model\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Name\"\u001b[0m: \u001b[32m\"Mistral 7B\"\u001b[0m,                                                                         \n",
       "                     \u001b[32m\"Number of parameters\"\u001b[0m: \u001b[32m\"7\\u2013billion\"\u001b[0m,                                                     \n",
       "                     \u001b[32m\"Number of max token\"\u001b[0m: \u001b[32m\"\"\u001b[0m,                                                                    \n",
       "                     \u001b[32m\"Architecture\"\u001b[0m: \u001b[1m[\u001b[0m                                                                             \n",
       "                         \u001b[32m\"grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,                                                          \n",
       "                         \u001b[32m\"sliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m                                                          \n",
       "                     \u001b[1m]\u001b[0m                                                                                             \n",
       "                 \u001b[1m}\u001b[0m,                                                                                                \n",
       "                 \u001b[32m\"Usage\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Use case\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,                                                                               \n",
       "                     \u001b[32m\"Licence\"\u001b[0m: \u001b[32m\"Apache 2.0\"\u001b[0m                                                                       \n",
       "                 \u001b[1m}\u001b[0m                                                                                                 \n",
       "             \u001b[1m}\u001b[0m                                                                                                     \n",
       "                                                                                                                   \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS START ****************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS START ****************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Time to generate response:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>1951s                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Time to generate response:   \u001b[1;36m1.\u001b[0m1951s                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Tokens per second:           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.3482</span> tokens/s                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Tokens per second:           \u001b[1;36m85.3482\u001b[0m tokens/s                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Input tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Input tokens:                \u001b[1;36m272\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Output tokens:               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Output tokens:               \u001b[1;36m102\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Total tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">374</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Total tokens:                \u001b[1;36m374\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS END ******************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS END ******************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- Ollama Response End ----------                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- Ollama Response End ----------                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Messages to AgentMemory                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Added \u001b[1;36m2\u001b[0m Messages to AgentMemory                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Added AgentRun to AgentMemory                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Added AgentRun to AgentMemory                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> --**-- Logging Agent Run                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m --**-- Logging Agent Run                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> *********** Agent Run End: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">598206ad-718f-42b6-942e-2ce0ebb122f1</span> ***********                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m *********** Agent Run End: \u001b[93m598206ad-718f-42b6-942e-2ce0ebb122f1\u001b[0m ***********                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- Ollama Response Start ----------                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- Ollama Response Start ----------                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== system ==============                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== system ==============                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> You extract structured information.                                                                       \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Extract and output structured information from the provided text with your tools.                       \n",
       "         - Use markdown to format your answers.                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m You extract structured information.                                                                       \n",
       "                                                                                                                   \n",
       "         ## Instructions                                                                                           \n",
       "         - Extract and output structured information from the provided text with your tools.                       \n",
       "         - Use markdown to format your answers.                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== user ==============                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== user ==============                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> We introduce Mistral 7B, a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>–billion-parameter language model engineered for                              \n",
       "         superior performance and efficiency. Mistral 7B outperforms the best open 13B                             \n",
       "         model <span style=\"font-weight: bold\">(</span>Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> across all evaluated benchmarks, and the best released 34B                                \n",
       "         model <span style=\"font-weight: bold\">(</span>Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> in reasoning, mathematics, and code generation. Our model                                 \n",
       "         leverages grouped-query attention <span style=\"font-weight: bold\">(</span>GQA<span style=\"font-weight: bold\">)</span> for faster inference, coupled with sliding                        \n",
       "         window attention <span style=\"font-weight: bold\">(</span>SWA<span style=\"font-weight: bold\">)</span> to effectively handle sequences of arbitrary length with a                         \n",
       "         reduced inference cost. We also provide a model fine-tuned to follow instructions,                        \n",
       "         Mistral 7B – Instruct, that surpasses Llama <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> 13B – chat model both on human and                          \n",
       "         automated benchmarks. Our models are released under the Apache <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span> license.                               \n",
       "         Code: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/mistralai/mistral-src</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                          \n",
       "         <span style=\"color: #000000; text-decoration-color: #000000\">Webpage: &lt;</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://mistral.ai/news/announcing-mistral-7b/</span><span style=\"font-weight: bold\">&gt;</span>                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m We introduce Mistral 7B, a \u001b[1;36m7\u001b[0m–billion-parameter language model engineered for                              \n",
       "         superior performance and efficiency. Mistral 7B outperforms the best open 13B                             \n",
       "         model \u001b[1m(\u001b[0mLlama \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m across all evaluated benchmarks, and the best released 34B                                \n",
       "         model \u001b[1m(\u001b[0mLlama \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m in reasoning, mathematics, and code generation. Our model                                 \n",
       "         leverages grouped-query attention \u001b[1m(\u001b[0mGQA\u001b[1m)\u001b[0m for faster inference, coupled with sliding                        \n",
       "         window attention \u001b[1m(\u001b[0mSWA\u001b[1m)\u001b[0m to effectively handle sequences of arbitrary length with a                         \n",
       "         reduced inference cost. We also provide a model fine-tuned to follow instructions,                        \n",
       "         Mistral 7B – Instruct, that surpasses Llama \u001b[1;36m2\u001b[0m 13B – chat model both on human and                          \n",
       "         automated benchmarks. Our models are released under the Apache \u001b[1;36m2.0\u001b[0m license.                               \n",
       "         Code: \u001b[1m<\u001b[0m\u001b[4;94mhttps:\u001b[0m\u001b[4;94m//github.com/mistralai/mistral-src\u001b[0m\u001b[39m>\u001b[0m                                                          \n",
       "         \u001b[39mWebpage: <\u001b[0m\u001b[4;94mhttps://mistral.ai/news/announcing-mistral-7b/\u001b[0m\u001b[1m>\u001b[0m                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== assistant ==============                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== assistant ==============                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Tool Calls: <span style=\"font-weight: bold\">[</span>                                                                                             \n",
       "           <span style=\"font-weight: bold\">{</span>                                                                                                       \n",
       "             <span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"function\"</span>,                                                                                   \n",
       "             <span style=\"color: #008000; text-decoration-color: #008000\">\"function\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                         \n",
       "               <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"predict_nuextract\"</span>,                                                                        \n",
       "               <span style=\"color: #008000; text-decoration-color: #008000\">\"arguments\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"input_text\\\": \\\"We introduce Mistral 7B, a 7\\\\u2013billion-parameter language model</span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">engineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model (Llama </span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">2) across all evaluated benchmarks, and the best released 34B model (Llama 1) in reasoning, mathematics, </span> \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with </span>\n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced </span>        \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B \\\\u2013 Instruct, </span>  \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">that surpasses Llama 2 13B \\\\u2013 chat model both on human and automated benchmarks. Our models are </span>     \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">released under the Apache 2.0 license. Code: https://github.com/mistralai/mistral-src Webpage: </span>           \n",
       "         <span style=\"color: #008000; text-decoration-color: #008000\">https://mistral.ai/news/announcing-mistral-7b/\\\"}\"</span>                                                        \n",
       "             <span style=\"font-weight: bold\">}</span>                                                                                                     \n",
       "           <span style=\"font-weight: bold\">}</span>                                                                                                       \n",
       "         <span style=\"font-weight: bold\">]</span>                                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Tool Calls: \u001b[1m[\u001b[0m                                                                                             \n",
       "           \u001b[1m{\u001b[0m                                                                                                       \n",
       "             \u001b[32m\"type\"\u001b[0m: \u001b[32m\"function\"\u001b[0m,                                                                                   \n",
       "             \u001b[32m\"function\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                         \n",
       "               \u001b[32m\"name\"\u001b[0m: \u001b[32m\"predict_nuextract\"\u001b[0m,                                                                        \n",
       "               \u001b[32m\"arguments\"\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\"input_text\\\": \\\"We introduce Mistral 7B, a 7\\\\u2013billion-parameter language model\u001b[0m\n",
       "         \u001b[32mengineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLlama \u001b[0m\n",
       "         \u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m across all evaluated benchmarks, and the best released 34B model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLlama 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in reasoning, mathematics, \u001b[0m \n",
       "         \u001b[32mand code generation. Our model leverages grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for faster inference, coupled with \u001b[0m\n",
       "         \u001b[32msliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to effectively handle sequences of arbitrary length with a reduced \u001b[0m        \n",
       "         \u001b[32minference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B \\\\u2013 Instruct, \u001b[0m  \n",
       "         \u001b[32mthat surpasses Llama 2 13B \\\\u2013 chat model both on human and automated benchmarks. Our models are \u001b[0m     \n",
       "         \u001b[32mreleased under the Apache 2.0 license. Code: https://github.com/mistralai/mistral-src Webpage: \u001b[0m           \n",
       "         \u001b[32mhttps://mistral.ai/news/announcing-mistral-7b/\\\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m                                                        \n",
       "             \u001b[1m}\u001b[0m                                                                                                     \n",
       "           \u001b[1m}\u001b[0m                                                                                                       \n",
       "         \u001b[1m]\u001b[0m                                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== tool ==============                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== tool ==============                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span>     <span style=\"font-weight: bold\">{</span>                                                                                                     \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Model\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Mistral 7B\"</span>,                                                                         \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of parameters\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"7\\u2013billion\"</span>,                                                     \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Number of max token\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,                                                                    \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Architecture\"</span>: <span style=\"font-weight: bold\">[</span>                                                                             \n",
       "                         <span style=\"color: #008000; text-decoration-color: #008000\">\"grouped-query attention (GQA)\"</span>,                                                          \n",
       "                         <span style=\"color: #008000; text-decoration-color: #008000\">\"sliding window attention (SWA)\"</span>                                                          \n",
       "                     <span style=\"font-weight: bold\">]</span>                                                                                             \n",
       "                 <span style=\"font-weight: bold\">}</span>,                                                                                                \n",
       "                 <span style=\"color: #008000; text-decoration-color: #008000\">\"Usage\"</span>: <span style=\"font-weight: bold\">{</span>                                                                                        \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Use case\"</span>: <span style=\"font-weight: bold\">[]</span>,                                                                               \n",
       "                     <span style=\"color: #008000; text-decoration-color: #008000\">\"Licence\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Apache 2.0\"</span>                                                                       \n",
       "                 <span style=\"font-weight: bold\">}</span>                                                                                                 \n",
       "             <span style=\"font-weight: bold\">}</span>                                                                                                     \n",
       "                                                                                                                   \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m     \u001b[1m{\u001b[0m                                                                                                     \n",
       "                 \u001b[32m\"Model\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Name\"\u001b[0m: \u001b[32m\"Mistral 7B\"\u001b[0m,                                                                         \n",
       "                     \u001b[32m\"Number of parameters\"\u001b[0m: \u001b[32m\"7\\u2013billion\"\u001b[0m,                                                     \n",
       "                     \u001b[32m\"Number of max token\"\u001b[0m: \u001b[32m\"\"\u001b[0m,                                                                    \n",
       "                     \u001b[32m\"Architecture\"\u001b[0m: \u001b[1m[\u001b[0m                                                                             \n",
       "                         \u001b[32m\"grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,                                                          \n",
       "                         \u001b[32m\"sliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m                                                          \n",
       "                     \u001b[1m]\u001b[0m                                                                                             \n",
       "                 \u001b[1m}\u001b[0m,                                                                                                \n",
       "                 \u001b[32m\"Usage\"\u001b[0m: \u001b[1m{\u001b[0m                                                                                        \n",
       "                     \u001b[32m\"Use case\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,                                                                               \n",
       "                     \u001b[32m\"Licence\"\u001b[0m: \u001b[32m\"Apache 2.0\"\u001b[0m                                                                       \n",
       "                 \u001b[1m}\u001b[0m                                                                                                 \n",
       "             \u001b[1m}\u001b[0m                                                                                                     \n",
       "                                                                                                                   \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ============== assistant ==============                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ============== assistant ==============                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span>                                                                                                           \n",
       "         **Model:**                                                                                                \n",
       "         - **Name:** Mistral 7B                                                                                    \n",
       "         - **Number of parameters:** <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>-billion                                                                     \n",
       "         - **Architecture:** Grouped-query attention <span style=\"font-weight: bold\">(</span>GQA<span style=\"font-weight: bold\">)</span> and sliding window attention <span style=\"font-weight: bold\">(</span>SWA<span style=\"font-weight: bold\">)</span>                      \n",
       "                                                                                                                   \n",
       "         **Usage:**                                                                                                \n",
       "         - **Use case:** N/A                                                                                       \n",
       "         - **Licence:** Apache <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>                                                                                 \n",
       "                                                                                                                   \n",
       "         The provided text does not mention the number of maximum tokens for Mistral 7B model.                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m                                                                                                           \n",
       "         **Model:**                                                                                                \n",
       "         - **Name:** Mistral 7B                                                                                    \n",
       "         - **Number of parameters:** \u001b[1;36m7\u001b[0m-billion                                                                     \n",
       "         - **Architecture:** Grouped-query attention \u001b[1m(\u001b[0mGQA\u001b[1m)\u001b[0m and sliding window attention \u001b[1m(\u001b[0mSWA\u001b[1m)\u001b[0m                      \n",
       "                                                                                                                   \n",
       "         **Usage:**                                                                                                \n",
       "         - **Use case:** N/A                                                                                       \n",
       "         - **Licence:** Apache \u001b[1;36m2.0\u001b[0m                                                                                 \n",
       "                                                                                                                   \n",
       "         The provided text does not mention the number of maximum tokens for Mistral 7B model.                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS START ****************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS START ****************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Time to generate response:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.</span>3262s                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Time to generate response:   \u001b[1;36m5.\u001b[0m3262s                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Tokens per second:           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.5221</span> tokens/s                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Tokens per second:           \u001b[1;36m16.5221\u001b[0m tokens/s                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Input tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Input tokens:                \u001b[1;36m618\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Output tokens:               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span>                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Output tokens:               \u001b[1;36m88\u001b[0m                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> * Total tokens:                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">706</span>                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m * Total tokens:                \u001b[1;36m706\u001b[0m                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> **************** METRICS END ******************                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m **************** METRICS END ******************                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> ---------- Ollama Response End ----------                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m ---------- Ollama Response End ----------                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> Messages to AgentMemory                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Added \u001b[1;36m4\u001b[0m Messages to AgentMemory                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Added AgentRun to AgentMemory                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m Added AgentRun to AgentMemory                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> --**-- Logging Agent Run                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m --**-- Logging Agent Run                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> *********** Agent Run End: <span style=\"color: #ffff00; text-decoration-color: #ffff00\">6ffdbc1c-c9d2-4f9a-aa18-6caf9a8f99ea</span> ***********                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mDEBUG   \u001b[0m *********** Agent Run End: \u001b[93m6ffdbc1c-c9d2-4f9a-aa18-6caf9a8f99ea\u001b[0m ***********                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(extract_agent.print_response(example_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
