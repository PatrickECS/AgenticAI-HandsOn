{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ada9d88-18f4-47df-b64e-f68555474869",
   "metadata": {},
   "source": [
    "# Structured generation and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43405c9-bce8-409e-a5ea-0bf203c61be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rich.pretty import pprint\n",
    "from phi.agent import Agent\n",
    "from phi.model.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d362ccf1-c013-4786-bcf6-aae1c466b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_HOST=\"localhost\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e42cb0-d603-47e9-b6d8-b9f8fdfa0706",
   "metadata": {},
   "source": [
    "### Structured Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d965daa2-842e-4e60-9855-25ef4b50748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6d572-8180-4430-a426-c45171e1e2b1",
   "metadata": {},
   "source": [
    "We'll define our structured object with a simple class derived from pydantic's BaseModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd5ac6d-4f84-4b4e-bab1-8930274fa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n",
    "    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n",
    "    genre: str = Field(\n",
    "        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n",
    "    )\n",
    "    name: str = Field(..., description=\"Give a name to this movie\")\n",
    "    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n",
    "    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ffbb8-ec2b-4517-a2d4-142d165786bc",
   "metadata": {},
   "source": [
    "Now we define the agent and give it an instruction. The response_model should be our MovieScript class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b6ed27-7067-4af9-baf0-aa9e3ad9081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent that uses JSON mode\n",
    "movie_agent = Agent(\n",
    "    #model=Ollama(id=\"smollm2\"), # how smol can you go?\n",
    "    model=Ollama(id=\"hermes3:8b-llama3.1-q8_0\", host=OLLAMA_HOST),\n",
    "    description=\"You write movie scripts.\",\n",
    "    markdown=False,\n",
    "    instructions=[\"Only output JSON, no json_object tag.\"],\n",
    "    response_model=MovieScript,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de825cc-f2d3-42c0-9299-fb25b5365891",
   "metadata": {},
   "source": [
    "We don't need function-calling or tools for this. This will all done with prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a670e35-0c14-4bbd-8e90-1597450c0d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'You write movie scripts.\\n\\n## Instructions\\n- Only output JSON, no json_object tag.\\n\\nProvide your output as a JSON containing the following fields:\\n&lt;json_fields&gt;\\n[\"setting\", \"ending\", \"genre\", \"name\", \"characters\", \"storyline\"]\\n&lt;/json_fields&gt;\\nHere are the properties for each field:\\n&lt;json_field_properties&gt;\\n{\\n  \"setting\": {\\n    \"description\": \"Provide a nice setting for a blockbuster movie.\",\\n    \"type\": \"string\"\\n  },\\n  \"ending\": {\\n    \"description\": \"Ending of the movie. If not available, provide a happy ending.\",\\n    \"type\": \"string\"\\n  },\\n  \"genre\": {\\n    \"description\": \"Genre of the movie. If not available, select action, thriller or romantic comedy.\",\\n    \"type\": \"string\"\\n  },\\n  \"name\": {\\n    \"description\": \"Give a name to this movie\",\\n    \"type\": \"string\"\\n  },\\n  \"characters\": {\\n    \"description\": \"Name of characters for this movie.\",\\n    \"items\": {\\n      \"type\": \"string\"\\n    },\\n    \"type\": \"array\"\\n  },\\n  \"storyline\": {\\n    \"description\": \"3 sentence storyline for the movie. Make it exciting!\",\\n    \"type\": \"string\"\\n  }\\n}\\n&lt;/json_field_properties&gt;\\nStart your response with `{` and end it with `}`.\\nYour output will be passed to json.loads() to convert it to a Python object.\\nMake sure it only contains valid JSON.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'You write movie scripts.\\n\\n## Instructions\\n- Only output JSON, no json_object tag.\\n\\nProvide your output as a JSON containing the following fields:\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mjson_fields\u001b[0m\u001b[32m>\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"setting\", \"ending\", \"genre\", \"name\", \"characters\", \"storyline\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n</json_fields>\\nHere are the properties for each field:\\n<json_field_properties>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"setting\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"Provide a nice setting for a blockbuster movie.\",\\n    \"type\": \"string\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \"ending\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"Ending of the movie. If not available, provide a happy ending.\",\\n    \"type\": \"string\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \"genre\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"Genre of the movie. If not available, select action, thriller or romantic comedy.\",\\n    \"type\": \"string\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \"name\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"Give a name to this movie\",\\n    \"type\": \"string\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \"characters\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"Name of characters for this movie.\",\\n    \"items\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n      \"type\": \"string\"\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n    \"type\": \"array\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \"storyline\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"description\": \"3 sentence storyline for the movie. Make it exciting!\",\\n    \"type\": \"string\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n</json_field_properties\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\nStart your response with `\u001b[0m\u001b[32m{\u001b[0m\u001b[32m` and end it with `\u001b[0m\u001b[32m}\u001b[0m\u001b[32m`.\\nYour output will be passed to json.loads\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to convert it to a Python object.\\nMake sure it only contains valid JSON.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(movie_agent.get_system_message().content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c996bead-4493-47de-bae5-39f4ae403741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieScript(setting='Darmstadt, Germany', ending='The protagonist manages to expose the corrupt tech company and bring them to justice.', genre='tech thriller', name='Cyber Conspiracy', characters=['Lena Hoffman - Cybersecurity Expert', 'Max Schneider - Journalist', 'Oliver Meyer - CEO of Tech Giant'], storyline=\"In Darmstadt, a brilliant cybersecurity expert discovers a sinister conspiracy within the city's largest tech company. As she works to expose their illicit activities, she forms an unlikely alliance with a tenacious journalist. Together, they must risk everything to prevent the company from unleashing a dangerous new technology on the world.\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Get the response in a variable\n",
    "res = movie_agent.run(\"A tech thriller in Darmstadt\")\n",
    "pprint(res.content)\n",
    "\n",
    "#movie_agent.print_response(\"A tech thriller in Darmstadt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a02d2-7b4f-454f-8086-d023cee546c9",
   "metadata": {},
   "source": [
    "### Structured extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9b329e-3b11-4d35-9c8f-fe3da8e4b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_agent = Agent(\n",
    "    #model=Ollama(id=\"sroecker/nuextract-tiny-v1.5\", host=OLLAMA_HOST),\n",
    "    model=Ollama(id=\"iodose/nuextract-v1.5\", host=OLLAMA_HOST, options={\"temperature\": 0}),\n",
    "    markdown=False,\n",
    "    structured_outputs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49918cb6-840b-4c69-99c5-491ac6ac9599",
   "metadata": {},
   "source": [
    "We'll have to define a simple helper function that produces the template needed for NuExtract models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84febaa3-1c68-4d1d-ad47-ee8c350320a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nuextract(input_text):\n",
    "    json_template = \"\"\"\n",
    "    {\n",
    "        \"Model\": {\n",
    "            \"Name\": \"\",\n",
    "            \"Number of parameters\": \"\",\n",
    "            \"Number of max token\": \"\",\n",
    "            \"Architecture\": []\n",
    "        },\n",
    "        \"Usage\": {\n",
    "            \"Use case\": [],\n",
    "            \"Licence\": \"\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    template = f\"\"\"<|input|>\\n### Template:\\n{json_template}\\n### Text:\\n{input_text}\\n\\n<|output|>\"\"\"\n",
    "\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63755fa3-3939-43c9-8ed6-d8cace52ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"We introduce Mistral 7B, a 7–billion-parameter language model engineered for\n",
    "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
    "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
    "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
    "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
    "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
    "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
    "Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and\n",
    "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
    "Code: <https://github.com/mistralai/mistral-src>\n",
    "Webpage: <https://mistral.ai/news/announcing-mistral-7b/>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763ab53-3041-4401-89fb-e08836961261",
   "metadata": {},
   "source": [
    "Let's have a look at the exact prompt that will be fed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa78238e-2029-487e-a3bd-a5ee1e93475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|input|>\n",
      "### Template:\n",
      "\n",
      "    {\n",
      "        \"Model\": {\n",
      "            \"Name\": \"\",\n",
      "            \"Number of parameters\": \"\",\n",
      "            \"Number of max token\": \"\",\n",
      "            \"Architecture\": []\n",
      "        },\n",
      "        \"Usage\": {\n",
      "            \"Use case\": [],\n",
      "            \"Licence\": \"\"\n",
      "        }\n",
      "    }\n",
      "    \n",
      "### Text:\n",
      "We introduce Mistral 7B, a 7–billion-parameter language model engineered for\n",
      "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
      "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
      "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
      "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
      "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
      "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
      "Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and\n",
      "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
      "Code: <https://github.com/mistralai/mistral-src>\n",
      "Webpage: <https://mistral.ai/news/announcing-mistral-7b/>\n",
      "\n",
      "<|output|>\n"
     ]
    }
   ],
   "source": [
    "print(predict_nuextract(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7a9cc0-a758-4cd1-adbc-17b7256d222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_agent.print_response(predict_nuextract(example_text)) # this doesn't work in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64489f95-38dd-4c75-b384-021b61a19975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': {'Architecture': ['grouped-query attention (GQA)',\n",
      "                            'sliding window attention (SWA)'],\n",
      "           'Name': 'Mistral 7B',\n",
      "           'Number of max token': '',\n",
      "           'Number of parameters': '7 billion'},\n",
      " 'Usage': {'Licence': 'Apache 2.0', 'Use case': []}}\n"
     ]
    }
   ],
   "source": [
    "result = extract_agent.run(predict_nuextract(example_text))\n",
    "pprint(json.loads(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac13d8f-8fce-4dad-bb40-98984ee98b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
